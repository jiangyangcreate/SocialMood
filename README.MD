# 代码说明

该项目适合作为小型的项目原型，适合教学和练手。

最初这个项目的灵感源于我的个人需求，我需要一个工具来查看主流话题，同时又不想下载一堆 APP 来接收推送。源项目最终的数据会以邮件的形式发送到我的邮箱，这里延申为使用github pages来展示。

项目开源地址：[https://github.com/jiangyangcreate/SocialMood](https://github.com/jiangyangcreate/SocialMood)

项目查看地址：[https://jiangyangcreate.github.io/SocialMood/](https://jiangyangcreate.github.io/SocialMood/)

## 使用流程

```bash
# 安装依赖
cd python
python setup.py

# 运行数据抓取，生成静态网页：html/charts.html
python crawler.py
```

### 依赖安装

所需依赖可以通过 `setup.py` 下载安装。因为有些模块不是pip就算安装好的。

### 主要功能

该系统的主要功能包括：
- **抓取热搜数据**：从微博、抖音、B站等平台抓取热搜数据。

这里也可以通过API获取，爬取注意不要变成DDOS攻击。

- **数据处理**：使用 Pandas 进行数据清洗与处理。

使用pandas主要是处理一些文本型的数据，譬如10万要换算为100000。

使用jieba分词用于后续词云图生成，需要剔除一些单字与标点符号。当然，最近b站很喜欢在标题中加空格，所以要先去空格再分词。

有些数据的热度值还没计算出来，可以使用幂律分布的线性回归填补热度缺失值。这里使用指数回归、普通线性回归效果都不好。

- **情绪分析**：监测和分析公众情绪。经过实测，发现最好的 API 接口也不如普通的大模型，因此在这个项目中选择了 **Qwen2.5** 作为情绪分析的核心。

算出单条标题的情绪数值之后，标准化到 `(-1,1)` 这个区间之中。最后通过热度与排名计算出对社会的情感影响力。正数数则是积极影响，负数则是负面影响。

以上代码均在 `crawler.py`。

### 数据存储

系统使用 `sqlite3` 保存中间数据，相关代码在 `database.py` 中，数据文件为 `news.db`，包含两张表：
- **news**：清洗后的可用数据。
- **raw_html**：原始网页数据。

这样可以保证速度的同时，可以保持文件夹的整洁，如果数据量大可以直接平滑的迁移到正式数据库中。

为了通过gitpages展示数据，我还将数据导出为 `json` 文件，这样可以直接在gitpages上展示。


### 数据可视化

接下来绘制一些图表，包括：
- 各个平台的情绪红绿图。
- 公众情绪的涨跌折线图。
- 每日全网词云图。

通过pyecharts的脚手架，导出为静态网页。


# 代码设置

随着时间的推移，爬虫部分的代码可能需要自己修改。